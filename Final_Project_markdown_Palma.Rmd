---
title: "PSYC 746-Final Project Demo"
author: "Pauline Palma"
date: "03/04/2020"
output: html_document
---

``````{r setup, include=FALSE}
knitr::opts_chunk$set(fig_with = 12, fig.height = 6)

library(dplyr)
library(lme4)
library(lmerTest)
library(lattice)
library(tidyverse)
library(wesanderson)
library(effects)
library(papaja)
options(scipen = 999)
```

# <span style="color: purple;"> 1. Description of the learning objectives</span> 

Welcome to this demo!

Today, you will learn about *cross-classified multilevel models*, a type of model that is commonly found in various domains of experimental psychology. We will use an example from psycholinguistics, where this type of MLM is common.

* What is a cross-classified multilevel model?
A cross-classified multilevel model allows one to estimate the unique influence of two
distinct Level 2 clusters. For instance, cross-classified MLM have been used in social psychology to assess variance in social impression formation (for a review, see Xie et al., 2018). In a social interaction, the impressions formed depend both on perceiver and on target characteristics, such as race and gender. Cross-classified MLM are especially useful there, as they allow for the partitioning of variance in impressions between perceivers and targets. 

In psycholinguistics, cross-classified MLM allow researchers to estimate the unique influence of individual participants and of individual items, such as words or sentences. This is especially useful, as psycholinguists are usually interested in both participants' characteristics (e.g., their age, native language, etc.) and items' characteristics (e.g., word length, frequency, etc.). A typical data structure in psycholinguistics involves multiple observations (Level 1) per participant (Level 2) and multiple observations per item (Level 2) (Baayen, Davidson, & Bates, 2008). It is important to emphasize that the two level 2 clusters are the primary units of interest for psycholinguists, whereas level 1 units (observations/trials) are usually not.

* In the present demo, we try to model total reading time (an eye-tracking measure) as a function of participant's native language and item's sentence context. Cross-classified MLM allow us to account for participant variability (e.g., some participants might be slower than others) and for item variability (e.g., some words might be less familiar to the participants).

# <span style="color: purple;"> 2. Research context and questions</span>
Human languages are inherently ambiguous. An important aspect of language processing is to make sense of this ambiguity. For example, when presented with the homonym sage, one must choose between the meaning ‘herb’ and the meaning ‘wise man’. Research on monolingual readers has shown that these multiple meanings are activated in parallel, which generates competition for meaning selection (e.g., Duffy, Kambe & Rayner, 2001; Rayner, Pacht & Duffy, 1994). Contextual sentence has been shown to cue meaning selection, hence reducing reading times on the ambiguous word (Rayner et al., 1994).

Importantly, reading speed is also impacted by participants' characteristics. For instance, non-native readers usually exhibit slower reading time compared to native readers, due to lower reading proficiency (see Brysbaert, 2019, for a review). Older adults are also slower compared to younger readers, due to slower processing speed (see Rossi & Diaz, 2016, for a review). There is also some evidence that contextual sentence specifically impacts reading times for ambiguous words in non-native speakers (Palma, Whitford, & Titone, 2019; see also Arêas da Luz Fontes & Schwartz, 2010, 2015; Schwartz, Yeh, & Shaw, 2008). However, it is unclear whether these effects extend to older bilingual speakers, as participants in these studies were young adults (18-35 years old). Because the effects of bilingualism have been shown to change across the lifespan (Whitford & Titone, 2019), it would be interesting to extend these results to older samples. 

The goal with this project is to analyze how bilingual older adults (60+ years old) process ambiguous English words during natural reading. Older bilingual adults read English sentences containing homonyms on a screen, while their eye movements were recorded. Participants were either French-English (reading in their second language) or English-French (reading in their first language) older bilinguals. The homonyms were embedded in sentences that either contained a modifier (e.g., adjective) related to one of the two meanings (e.g., Mary liked the fresh sage), or did not contain such a modifier (e.g., Mary liked the sage).

We constructed three models (including a null model) to answer four specific research questions: 

a) Do bilingual older adults process ambiguous words differently when they are embedded in sentences that clarify their meaning or not? -> Model 2
b) Does the effect of context vary across participants? -> Model 3
c) Does native language modulate the processing of ambiguous words? -> Model 3
d) Does context impact the processing of ambiguous words regardless of native language? -> Model 3

# <span style="color: purple;">3. Description of the variables</span>
```{r}
PSYC746_final <- read.csv("PSYC746_final.csv")
```

```{r}
summary(PSYC746_final)
length(unique(PSYC746_final$Subject))
length(unique(PSYC746_final$ITEM))
```
There are 32 participants and 64 items in the dataset. There are 1988 lines, representing the 1988 trials completed by all participants.

* X: trial number 
* Subject: Subject ID number 
* ITEM: Item ID number 
* log_TRT_target: log of the total reading time on the target ambiguous word. Total reading time is the sum of all the fixations made on the word in milliseconds, measured with an eye-tracking system. This measure is thought to reflect ambiguity resolution and meaning integration processes. It was logged to correct for skew. This is the dependent variable in the models.
* Group_dev: the language group the participant belongs to. All participants know both English and French. For some, English is the first language they acquired (English-French bilinguals), for other, French is the first language they acquired (French-English bilinguals). This was assessed via a language history questionnaire. This variable was effects-coded (-.5: English-French bilinguals, .5: French-English bilinguals). This is a characteristic of participants (level-2) and a predictor.
* Context_dev: the sentence context in which the target ambiguous word was embedded, that is, whether the sentence contained a modifier (usually, an adjective) related to one of the homonym’s meanings or not. This variable was effects-coded (-.5: no modifier, .5: modifier). E.g., "Mary liked the **fresh sage** vs. "Mary liked the sage". This is a characteristic of items (level-2) and a predictor.

# <span style="color: purple;">4. Description/visual of the data structure</span> 

We first verify the functional form of the variables of interest by plotting them. 

* Dependent variable  
```{r, echo = FALSE, fig.width=8, fig.height = 5}
hist(PSYC746_final$log_TRT_target)
```
   
The DV is not perfectly normally distributed (skew to the right).


* Relationship predictors & dependent variable  

```{r, echo = FALSE, fig.width=6, fig.height = 4}
PSYC746_final$Context <- ifelse(PSYC746_final$Context_dev == -0.5, "No modifier", "Modifier")
PSYC746_final$Group <- ifelse(PSYC746_final$Group_dev == -0.5, "English-French bil", "French-English bil")

PSYC746_final %>% ggplot(mapping = aes(x = Context, y = log_TRT_target)) +
  geom_bar(stat="identity", position="dodge", aes(fill=Context_dev)) +
  facet_wrap(~Group) +
  labs(x="Context", y = "TRT of the target ambiguous word\n(log ms)", fill="") +
  coord_cartesian(ylim=c(6,9)) +
  theme_apa()+
  theme_bw(base_size = 20) +
  theme(legend.position = "none", axis.text.x = element_text(size = 16), 
        axis.text.y = element_text(size = 16), axis.title.x= element_text(size = 16),
        axis.title.y = element_text(size = 12), strip.text.x = element_text(size = 16),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(colour = "black", fill=NA, size=1))
  
```
   
Target ambiguous words are read slower when there is no modifier, although the difference between the modifier and the no modifier condition is reduced for French-English bilingual older adults.

* Correlation predictors & dependent variable
```{r}
PSYC746_final %>% 
  select(log_TRT_target, Group_dev, Context_dev) %>%
  cor()
```
* .20 correlation between Group and log TRT
* -.14 correlation between Context and log TRT  

* Individual scatterplots

**Effect of context by participant**

```{r, echo = FALSE, fig.width=10, fig.height = 6}
PSYC746_final %>% 
  ggplot() +
  geom_point(mapping = aes(x = Context, y = log_TRT_target)) +
  facet_wrap(~Subject) +
  coord_cartesian(ylim=c(4,10))
```
   
Most participants follow the expected pattern, in that they exhibit faster log TRT when Context = Modifier. Some participants (e.g., 19) do not seem to follow this pattern.  

**Effect of context by item**  

```{r, echo = FALSE, fig.width=10, fig.height = 6}
PSYC746_final %>% 
  ggplot() +
  geom_point(mapping = aes(x = Context, y = log_TRT_target)) +
  facet_wrap(~ITEM) +
  coord_cartesian(ylim=c(4,10))
```
   
Most items follow the expected pattern, in that they are associated with lower log TRT when a modifier related to one of their meanings is present in the sentence. Not all items follow this pattern (item 2, item 50 for example).

**Effect of language group by item**  

```{r, echo = FALSE, fig.width=12, fig.height = 6}
PSYC746_final %>% 
  ggplot() +
  geom_point(mapping = aes(x = Group, y = log_TRT_target)) +
  facet_wrap(~ITEM)+
  coord_cartesian(ylim=c(4,10))
```
   
The pattern is unclear--it looks like some items, but not all, were read faster by bilingual participants with English as their first language.

* Regression line

**Context by participant**  

```{r, echo = FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% 
  group_by(Subject) %>% 
ggplot(mapping = aes(x = Context_dev, y = log_TRT_target, colour = factor(Subject))) +
  geom_point(show.legend = FALSE) +
  geom_smooth(method = lm, se = FALSE, show.legend = FALSE)
```
   
At the subject level, a modifier in the sentence context (Context_dev = 0.5) is associated with decreased log TRT.

**Context by item**   

```{r,  message=FALSE, echo = FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% 
  group_by(ITEM) %>% 
ggplot(mapping = aes(x = Context_dev, y = log_TRT_target, colour = factor(ITEM))) +
  geom_point(show.legend = FALSE) +
  geom_smooth(method = lm, se = FALSE, show.legend = FALSE)
```
   
At the item level, it is less clear that a modifier in the sentence context (Context_dev = 0.5) is associated with decreased log TRT (some items are associated with higher log TRT in such sentence contexts.

**Language group by item**   

```{r,  echo = FALSE, message=FALSE, warning = FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% 
  group_by(ITEM) %>% 
ggplot(mapping = aes(x = Group_dev, y = log_TRT_target, colour = factor(ITEM))) +
  geom_point(show.legend = FALSE) +
  geom_smooth(method = lm, se = FALSE, show.legend = FALSE)
```
   
Items are associated with increased log TRT when they are read by French-English bilingual participants (Group_dev = 0.5).

# <span style="color: purple;">5. Models and interpretation</span> 

## a. Model 1 (null)
### Equation
The equation for a cross-classified model is different from the usual MLM equation. Below, we spelled out all the terms.

* L1: TRTi(j1k1) = 𝜋0(j1k1) + ei(j1k1)
* L2: 𝜋0(j1k1) = 𝜃000 + b0j10 + c00k1 

We estimate 4 parameters (1 fixed effect, 3 random effects) with this null model.
Level 1 is the trial level
* TRTi(j1k1) is the TRT of the trial for item j1 and participant k1
* 𝜋0(j1k1) is the expected value for TRT for this item and this participant
* ei(j1k1) is the error term, which accounts for error for variability with respect to participant and item level

Level2 is the cluster level: there are two distinct clusters, such that trials are grouped both under participants and under items.

* 𝜋0(j1k1) is the expected value for TRT, that can vary across participants and items, which allows the total variance of the model to be partitioned into that attributable to participants and items
* 𝜃000 is the grand mean for TRT, averaged across all items and participants
* b0j10 is the residual of the item j1 averaged across all participants (i.e., the difference between the grand mean and the TRT of target j1), which has variance tb00 * * c00k1 is the residual of participant k1 averaged across all items (i.e., the difference between the grand mean and the TRT of participant k1), which has variance tc00

* *Usually, cross-classified MLM also include another term, d0(j1k1), which is the interaction between item and participant variance in the model. However, to be able to estimate the random effect associated with this interaction requires repeated reading of a single item by each participant, in order to separate the variance associated with this interaction from the residual variance. In the present study, each participant read each item only once, so we are unable to estimate this component and it is fixed to zero (not estimated). We have therefore only have three variance terms in the model: variance across items, variance across participants, and variance of the L1 error term ei(j1k1).* 

### Model
```{r}
Null = lmer(log_TRT_target ~ 1+(1|Subject) + (1|ITEM), data=PSYC746_final, REML = T)
summary(Null)
```


### Interpretation
```{r}
exp(6.22055)
```

Interpretation:
The fixed effects table indicates that the expected average value for TRT, across all participants and items, is 6.22055 log ms, so 502.9798 ms. 
Notice that, in the random effects table, three random effects can be found: the random intercept for ITEM, the random intercept for Subject, and the residuals. Observation of these residuals suggests that an important amount of participant variability, and a reduced amount of item variability. This contrast is not surprising, and it is found commonly in psycholinguistic research--items were strictly controlled for a range of factors that impact reading time, such as length and frequency, among others, thereby reducing variability in reading times across items.

In what follows, we explore how important the clusters are in the MLM.  

### Exploration of the random effects

#### Participants
We first calculate the Intra-Class Correlation, in order to assess the proportion of variance that is explained by the clusters. The ICC is calculated slightly differently in a cross-classified MLM compared to a regular MLM, as it takes into account the presence of two clusters in the model. The ICC in a cross-classified data structure is calculated by dividing the random effect (by participant or by items) by the total variance (by participant + by item + residuals) (see Carson & Beeson, 2013; Locker et al., 2007).
```{r ICC participant}
(0.20575)/(0.20575+0.02596+0.27660)
```
40.48% of the total variance is explained by between-subject variability. 

We then calculate the Design effect to assess whether a cluster effect is present for participants. 

We first calculate the mean number of observation per participant
```{r}
x = as.data.frame(table(PSYC746_final$Subject))
mean(x$Freq)
```
Mean number of observations per participant = 62.125

```{r}
DEFF = 1+(62.125-1)*0.4047727
```
DEFF participants = 25.742

Because this number is much higher than 1, it suggests an important cluster effect for participants.

Effective sample size
```{r}
32/25.742
```
The effective sample size, when adjusted for participant clustering, is 1.243. This suggests high within-participant consistency in terms of reading times.

We then calculate the DEFT, in order to get a sense of how off our standard error estimate would be in linear model that would not include clustering.
```{r}
DEFT = sqrt(DEFF)
```
Standard errors are 5.074 times larger than we would estimate in a linear model that would not include clustering.

#### Items
We first calculate the ICC for the item cluster.
```{r ICC item}
(0.02596)/(0.02596+0.20575+0.27660)
```
5.11% of the total variance is explained by between-item variability.
40.48% 

We then calculate the Design effect to assess whether a cluster effect is present for items. We first calculate the mean number of observations per item.
```{r}
x = as.data.frame(table(PSYC746_final$ITEM))
mean(x$Freq)
```
Mean number of observations per item = 31.063

```{r}
DEFF2 = 1+0.0510712*(31.063-1)
```
DEFF items = 2.535
Because this number is higher than 1, it suggests that there is a cluster effect for items. 

Effective sample size
```{r}
64/2.535
```
The effective sample size, when adjusted for participant clustering, is 25.247.

We then calculate the DEFT, in order to get a sense of how off our standard error estimate would be in a linear model that would not include clustering.

```{r}
DEFT2 = sqrt(DEFF2)
```
Standard errors are 1.592 times larger than we would estimate in a linear model that would not include clustering.

Overall, these scores warrant the use of a MLM for this dataset. We therefore continue our analysis by adding a level-2 predictor to the null model.

## Model 2
### Equation
* L1: TRTi(j1k1) = 𝜋0(j1k1) + ei(j1k1)
* L2: 𝜋0(j1k1) = 𝜃000 + 𝜃001Contextj+ b0j10 + c00k1

In this model, we include the effects-coded level-2 predictor "Context_dev", capturing the difference between embedding sentence contexts with or without a modifier related to one of the homonym's meanings (e.g., Mary liked the fresh sage). This is represented by the parameter 𝜃001Contextj. Thus, we estimate 5 parameters in this model (2 fixed effects, 3 random effects). 
This model allows us to answer question a) Do bilingual older adults process ambiguous words differently when they are embedded in sentences that clarify their meaning or not? 

### Model
```{r}
Model2 = lmer(log_TRT_target ~ Context_dev +
                (1|Subject) + 
                (1|ITEM), data=PSYC746_final, REML = T)
summary(Model2)
```

```{r}
exp(6.22001)
```

### Interpretation
Remember that the predictor "Context_dev" is effects-coded (-.5 = no modifier, .5 = modifier present). 
The fixed effects table indicates that the expected average value for TRT across all participants and items, when Context_dev is at 0 (i.e., while controlling for sentence context), is 6.22001 log ms, so 502.7083 ms. 
There is a significant negative effect of Context_dev on expected TRT, suggesting that homonyms embedded in sentence contexts with a modifier related to one of their target meanings are read faster than compared to the average reading speed across both sentence contexts. In the next section, we plotted this effect. Observation of this plot suggests that bilingual older adults do process ambiguous words differently when they are embedded in sentences that include a modifier clarifying their meaning. 

### Visualization of the effect
```{r, include = FALSE, echo = FALSE}
ef <- as.data.frame(Effect(c("Context_dev"), Model2))
ef
ef$Context = ifelse(ef$Context_dev == -0.5, "No modifier", ifelse(ef$Context_dev == 0.5, "Modifier", "HDUEHEIQU"))
ef = subset(ef, Context != "HDUEHEIQU")
```

```{r, echo = FALSE, message=FALSE, warning = FALSE, fig.width=6, fig.height = 4}
ggplot(ef, aes(x=Context, y=fit)) +
  geom_bar(stat="identity", position="dodge", aes(fill=Context)) +
  scale_fill_manual(values = wes_palette("GrandBudapest2"))+
  geom_errorbar(aes(ymin=fit-se, ymax=fit+se), width=.3, size = .6) +
  labs(y="TRT of the target ambiguous word\n(log ms, fitted)", x = "Sentence context", fill="") +
  coord_cartesian(ylim=c(5,7)) +
  theme_apa()+
  theme_bw(base_size = 20) +
  theme(legend.position = "none", axis.text.x = element_text(size = 16), 
        axis.text.y = element_text(size = 16), axis.title.x= element_text(size = 16),
        axis.title.y = element_text(size = 12), strip.text.x = element_text(size = 16),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(colour = "black", fill=NA, size=1))
```
   
In order to reduce the length of this demo, we did not run additional checks on this model. However, we fully check model assumptions for model 3, our last model, and compare it to Model 2 and the null model in terms of fit.

## Model 3
### Equation
* L1: TRTi(j1k1) = 𝜋0(j1k1) + ei(j1k1)
* L2: 𝜋0(j1k1) = 𝜃000 + b0j10 + c00k1 + 𝜃001Contextj + 𝜃002Language groupk + c10k1 + 𝜃002Language groupk x 𝜃002Contextj 

We estimate 8 parameters in this model (4 fixed effects, 4 random effects). This model  includes a novel level 2 predictor for language group, capturing the difference between participants with English as their first vs. second language, represented by parameter 𝜃002Language groupk. We also added a random slope for Context_dev by participant, in order to assess whether the effect of context varies across participants, represented by parameter c10k1. Because we were interested in how the effect of sentence context depended on the effect of language group, we also included the interaction of these two predictors, represented by parameter 𝜃002Language groupk x 𝜃002Contextj.

Adding these parameters allows us to answer questions b), c) and d).
b) Does the effect of context vary across participants? 
c) Does native language modulate the processing of ambiguous words?
d) Does context impact the processing of ambiguous words regardless of native language?

### Model
```{r}
Model3 = lmer(log_TRT_target ~ Context_dev*Group_dev+
                (1+Context_dev||Subject) + 
                (1|ITEM), data=PSYC746_final, REML = T)
summary(Model3)
```

```{r}
exp(6.19294)
```

#### Interpretation
Inspection of the fixed effect table indicates that the expected value for log TRT when Context and Group are at 0 (i.e., for both sentence context type and both language groups), is 6.19294 log ms, so 489.2825ms.
As in Model 2, there is a significant negative effect of context on expected TRT, suggesting that homonyms embedded in sentence contexts with a modifier related to one of their target meanings are read faster than compared to the average reading speed across both sentence contexts.
The effect of language group does not reach significance, suggesting no  difference of French-English bilinguals, in terms of Log TRT, from the grand mean log TRT of the two language groups. This indicates that native language does not modulate the processing of ambiguous words (question c).
The interaction of language group and context also does not reach significance, suggesting that context does impacts the processing of ambiguous words regardless of native language (question d), as can be seen in the bar plot below.


#### Visualization of the interaction (non-significant)
```{r, echo = FALSE, include = FALSE}
ef <- as.data.frame(Effect(c("Context_dev", "Group_dev"), Model3))
ef
ef$Context = ifelse(ef$Context_dev == -0.5, "No modifier", ifelse(ef$Context_dev == 0.5, "Modifier", "HDUEHEIQU"))
ef$Group = ifelse(ef$Group_dev == -0.5, "English-French bil", ifelse(ef$Group_dev == 0.5, "French-English bil", "HDUEHEIQU"))

ef = subset(ef, Context != "HDUEHEIQU" & Group != "HDUEHEIQU")
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
ggplot(ef, aes(x=Context, y=fit)) +
  geom_bar(stat="identity", position="dodge", aes(fill=Context)) +
  scale_fill_manual(values = wes_palette("GrandBudapest2"))+
  geom_errorbar(aes(ymin=fit-se, ymax=fit+se), width=.3, size = .6) +
  labs(y="TRT of the target ambiguous word\n(log ms, fitted)", x = "Prior sentence context", fill="") +
  facet_wrap(~Group)+
  coord_cartesian(ylim=c(5,7)) +
  theme_apa()+
  theme_bw(base_size = 20) +
  theme(legend.position = "none", axis.text.x = element_text(size = 16), 
        axis.text.y = element_text(size = 16), axis.title.x= element_text(size = 16),
        axis.title.y = element_text(size = 12), strip.text.x = element_text(size = 16),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.border = element_rect(colour = "black", fill=NA, size=1))
```

#### 95% plausible values range for intercepts

##### How much do means vary across participants?
```{r}
SDx2 <- (2*(sqrt(0.190874)))
Upper_range <- 6.19294 + SDx2
lower_range <- 6.19294 - SDx2
```
The 95% plausible values range for participants means is 5.319-7.067 log ms.

##### How much do means vary across items?

```{r}
SDx2 <- (2*(sqrt(0.026274)))
Upper_range <- 6.19294 + SDx2
lower_range <- 6.19294 - SDx2
```
The 95% plausible values range for items means is 5.869-6.517 log ms. The smaller plausible value range for items means compared to participants means was expected, as items were strictly controlled.

### Model comparison

#### Deviance tests
```{r}
anova(Model2, Model3, refit = FALSE)
```
Model 3 is not superior to Model 2 in terms of fit (X2(3) = 1.524, p > .05). The Log likelihood of Model 2 and Model 3 are similar.

```{r}
anova(Null, Model2, refit = FALSE)
```

Model 2 is superior to the null model in terms of fit (X2(1) = 61.064, p < .001).

#### Profile confidence intervals
```{r}
confint(Model3, oldNames = FALSE) 
```
The profile confidence interval for language group, context*language group, and for the random slope for context by subject all include 0. This suggests that these predictors and the random slope do not contribute significantly to the model and allows us to answer "no" to question b (Does the effect of context vary across participants?). These results are also in line with the results of model comparison above--model 2, which does not include these parameters, does not have a worse fit than model 3 (but has better fit than the null model).

#### Difference in residuals
Model comparison suggests that Model 2 is superior to Model 3 in terms of fit. We now compare the residuals of Model 2 and 3.

```{r}
tau2change_p = 0.20535-0.190874
```
.014

```{r}
tau2change_i = 0.02621-0.026274
```
-.000

```{r}
sigma2change = 0.26718-0.266246
```
.001

Adding the language group predictor, the interaction between language group and context, and the random slope for context by participant does not really impact the residuals.

#### Variance reduction
We now assess by how much variance at level 1 and 2 is reduced in Model 3 compared to Model 2.

```{r}
L1_var_reduction <- sigma2change/0.26718
```
.003

```{r}
L2_var_reduction_p <- tau2change_p/0.20535
```
.070

```{r}
L2_var_reduction_i <- tau2change_i/0.02621
```
-.002

Adding the language group predictor, the interaction between language group and context, and the random slope for context by participant slightly reduces the variance explained by participant variability (-7%).

#### Conditional ICC
We now calculate the change in ICC caused by the addition of predictors and the random slope.
```{r}
conditionalICC_p = 0.190874/ (0.190874 + 0.026274+0.266246)
conditionalICC_i = 0.026274 / (0.026274 + 0.190874+ 0.266246)
```
In Model 3, 39.49% of the total variance is due to variability between subjects and 5.44% of the variance is due to variability between items. As a reminder, the ICC of the null model suggested that 40.48% of the total variance was due to variability between subjects and 5.11% of the total variance was explained by between-item variability. Therefore, Model 3 is associated with a slight decrease in the ICC by participant, and a slight increase of the ICC by item.

### Assumption checks

#### Distribution of L1 residuals
```{r, include = FALSE}
l1_residuals <- tibble::enframe(residuals(Model3))
PSYC746_final <- PSYC746_final %>% 
  bind_cols(l1_residuals) %>% 
  select(-name) %>% 
  rename(l1resid = value)
```

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% ggplot(mapping = aes(x = l1resid)) +
  geom_histogram()
```
   
L1 residuals look fairly normal.

#### Distribution of L2 residuals
```{r, echo = FALSE, fig.width=8, fig.height = 4}
par(mfrow=c(1,3))

PSYC746_finalByParticRanef <- ranef(Model3)$Subject[['(Intercept)']]
qqnorm(PSYC746_finalByParticRanef,  main = "participant intercepts") #2 weirdos
qqline(PSYC746_finalByParticRanef)

PSYC746_finalByParticRanef_slope <- ranef(Model3)$Subject[['Context_dev']]
qqnorm(PSYC746_finalByParticRanef_slope,  main = "participant slopes") #OK
qqline(PSYC746_finalByParticRanef_slope)

PSYC746_finalByItemRanef <- ranef(Model3)$ITEM[['(Intercept)']]
qqnorm(PSYC746_finalByItemRanef,  main = "item intercepts") #1 weirdo
qqline(PSYC746_finalByItemRanef)
```
   
There is a potential violation of the assumption of normality of residuals. There are two participants that should be flagged as outliers, and potentially one item that should be flagged as an outlier. 

This is confirmed by the plots of the L2 residuals below

**L2 residuals-participants (intercept)**

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
l2_residuals_p <- ranef(Model3)$Subject
l2_residuals_p %>% 
  ggplot(mapping = aes(x = `(Intercept)`)) +
  geom_histogram()
```
   
**L2 residuals - Items (intercept)**   

```{r, echo = FALSE, warning  = FALSE, message = FALSE, fig.width=6, fig.height = 4}
l2_residuals_i <- ranef(Model3)$ITEM
l2_residuals_i %>% 
  ggplot(mapping = aes(x = `(Intercept)`)) +
  geom_histogram()
```
   
**L2 residuals - Participants (slope)**

```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
l2_residuals_p %>% 
  ggplot(mapping = aes(x = Context_dev)) +
  geom_histogram()
```

#### Summary statistics L2 residuals

```{r}
summary(PSYC746_finalByParticRanef)
summary(PSYC746_finalByParticRanef_slope)
summary(PSYC746_finalByItemRanef)
```
   
All L2 residuals have a mean of 0 but their median is not 0, which suggests some nonnormality in their distribution.

#### Flag outliers-participants (intercept)

```{r, echo = FALSE, warning = FALSE, fig.width=6, fig.height = 4}
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

temp_int <- l2_residuals_p %>% 
  tibble::rownames_to_column(var="outlier") %>% 
  mutate(is_outlier = ifelse(is_outlier(`(Intercept)`), `(Intercept)`, as.numeric(NA)))
temp_int$outlier[which(is.na(temp_int$is_outlier))] <- as.numeric(NA)

ggplot(temp_int, aes(y = `(Intercept)`, x = 0)) +
  geom_boxplot()  +
  geom_text(aes(label = outlier), na.rm = TRUE, nudge_y = 0.2)
```
   
Participant 29 and 8 are outliers.

#### Flag outliers-items (intercept)
```{r, echo = FALSE, warning = FALSE, fig.width=6, fig.height = 4}
temp_int <- l2_residuals_i %>% 
  tibble::rownames_to_column(var="outlier") %>% 
  mutate(is_outlier = ifelse(is_outlier(`(Intercept)`), `(Intercept)`, as.numeric(NA)))
temp_int$outlier[which(is.na(temp_int$is_outlier))] <- as.numeric(NA)

ggplot(temp_int, aes(y = `(Intercept)`, x = 0)) +
  geom_boxplot()  +
  geom_text(aes(label = outlier), na.rm = TRUE, nudge_y = 0.2)
```
   
Item 2 is an outlier (this item is the word "axes").

#### Flag outliers-participants (slope)
```{r, echo = FALSE, fig.width=6, fig.height = 4}
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

temp_int <- l2_residuals_p %>% 
  tibble::rownames_to_column(var="outlier") %>% 
  mutate(is_outlier = ifelse(is_outlier(`Context_dev`), `Context_dev`, as.numeric(NA)))
temp_int$outlier[which(is.na(temp_int$is_outlier))] <- as.numeric(NA)

ggplot(temp_int, aes(y = `(Intercept)`, x = 0)) +
  geom_boxplot()  +
  geom_text(aes(label = outlier), na.rm = TRUE, nudge_y = 0.2)
```
   
No outlier flagged.

##### As an aside, what if we removed these outliers?
Removing both participants and item outliers creates a convergence issue (remember that our sample size is small to begin with). Thus, we first tried removing participants 8 and 29.

```{r}
Model3bis <- update(Model3, . ~ ., data=filter(PSYC746_final, Subject != c(8, 29)))
summary(Model3bis)
```
   
Removing outlier participants does not drastically change the effects: the effect of 
language Group, which did not reach significance in Model 3 (p = .06) is now at .10. The interaction coefficient is similar to the one in Model 3, and it still does not reach significance.

We also tried removing the outlier item.
```{r}
Model3bis <- update(Model3, . ~ ., data=filter(PSYC746_final, ITEM != 2))
summary(Model3bis)
```
   
Removing this item does not significantly impact the effects observed in Model 3.

#### Relatedness
In what follows, we checked whether:
* L2 predictors were unrelated to L2 residuals
* L2 predictors were not related to L1 residuals 
* L2 residuals were unrelated to L1 residuals
* L2 residuals were independent from one another and across L2 units

##### Relatedness of L2 predictors and L2 residuals
*Relatedness of L2 predictors (context) and L2 residuals (intercept participant)*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_residuals_rowname_p <- rownames_to_column(l2_residuals_p) %>% 
  rename("Subject" = rowname) %>%
  mutate("Subject" = as.integer(Subject)) %>% 
  rename(L2resid_p = '(Intercept)') %>%
  rename(L2resid_slope = 'Context_dev') %>%
  as_tibble()

l2_mix <- merge(l2_residuals_rowname_p, PSYC746_final, by = "Subject")

l2_mix %>% ggplot(mapping = aes(x = L2resid_p, y = Context_dev)) +
  geom_point() +
  labs(x = "Residuals participants", y = "Context")
cor.test(l2_mix$L2resid_p, l2_mix$Context_dev)
```
   
There is no significant correlation between L2 residuals by participant and Context.

*Relatedness of L2 predictors (group) and L2 residuals (intercept participant)*
```{r, echo = FALSE,fig.width=6, fig.height = 4}
l2_mix %>% ggplot(mapping = aes(x = L2resid_p, y = Group_dev)) +
  geom_point() +
  labs(x = "Residuals participants", y = "Group")
cor.test(l2_mix$L2resid_p, l2_mix$Group_dev) 
```
   
There is no significant correlation between L2 residuals by participant and Language Group.

*Relatedness of L2 predictor (context) and L2 residuals (intercept items)*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_residuals_rowname_i <- rownames_to_column(l2_residuals_i) %>% 
  rename("ITEM" = rowname) %>%
  mutate("ITEM" = as.integer(ITEM)) %>% 
  rename(L2resid_i = '(Intercept)') %>%
  as_tibble()

l2_mix <- merge(l2_residuals_rowname_i, PSYC746_final, by = "ITEM")

l2_mix %>% ggplot(mapping = aes(x = L2resid_i, y = Context_dev)) +
  geom_point() +
  labs(x = "Residuals items", y = "Context")
cor.test(l2_mix$L2resid_i, l2_mix$Context_dev) 
```
   
There is no significant correlation between L2 residuals by item and Context.

*Relatedness of L2 predictors (group) and L2 residuals (intercept items)*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix %>% ggplot(mapping = aes(x = L2resid_i, y = Group_dev)) +
  geom_point() +
  labs(x = "Residuals items", y = "Group")
cor.test(l2_mix$L2resid_i, l2_mix$Group_dev) 
```
   
There is no significant correlation between L2 residuals by item and Language Group.

*Relatedness of L2 predictor (context) and L2 residuals (slope context participant)*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix <- merge(l2_residuals_rowname_p, PSYC746_final, by = "Subject")
l2_mix %>% ggplot(mapping = aes(x = L2resid_slope, y = Context_dev)) +
  geom_point() +
  labs(x = "Residual slope by participants", y = "Context")
cor.test(l2_mix$L2resid_slope, l2_mix$Context_dev)
```
   
There is no significant correlation between L2 residuals (random slope for Context by participants) and Context.

*Relatedness of L2 predictor (group) and L2 residuals (slope context participant)*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix %>% ggplot(mapping = aes(x = L2resid_slope, y = Group_dev)) +
  geom_point() +
  labs(x = "Residual slope by participants", y = "Group")
cor.test(l2_mix$L2resid_slope, l2_mix$Group_dev)
```
   
There is no significant correlation between L2 residuals (random slope for Context by participants) and Language Group.

##### Relatedness of L2 predictors and L1 residuals

*Relatedness of L2 predictors (context) and L1 residuals*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% ggplot(mapping = aes(x = l1resid, y = Context_dev)) +
  geom_point() +
  labs(x = "Residuals", y = "Context")
cor.test(PSYC746_final$l1resid, PSYC746_final$Context_dev) 
```
   
There is no significant correlation between L1 residuals and Context.

*Relatedness of L2 predictors (group) and L1 residuals*
```{r, echo = FALSE, fig.width=6, fig.height = 4}
PSYC746_final %>% ggplot(mapping = aes(x = l1resid, y = Group_dev)) +
  geom_point() +
  labs(x = "Residuals", y = "Group")
cor.test(PSYC746_final$l1resid, PSYC746_final$Group_dev) 
```
   
There is no significant correlation between L1 residuals and Language Group.

##### Relatedness of L1 and L2 residuals
*Relatedness of L1 residuals and L2 residuals (intercept participants)*
```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
l2_residuals_rowname <- rownames_to_column(l2_residuals_p) %>% 
  rename("Subject" = rowname) %>%
  mutate("Subject" = as.integer(Subject)) %>% 
  rename(intercept_residual = `(Intercept)`) %>%
  rename(slope_residual = `Context_dev`) %>%
  as_tibble()

PSYC746_final <- full_join(PSYC746_final, l2_residuals_rowname, by = "Subject") 

PSYC746_final %>%
  ggplot() + 
  geom_point(mapping = aes(x = l1resid, y = intercept_residual))
cor.test(PSYC746_final$l1resid, PSYC746_final$intercept_residual) 
```
   
There is no significant correlation between L1 residuals and L2 residuals (random intercept by participant). Again, the two outliers are clearly identifiable. 

*Relatedness of L1 residuals and L2 residuals (intercept items)*
```{r, echo = FALSE, warning = FALSE, message = FALSE, fig.width=6, fig.height = 4}
l2_residuals_rowname2 <- rownames_to_column(l2_residuals_i) %>% 
  rename("ITEM" = rowname) %>%
  mutate("ITEM" = as.integer(ITEM)) %>% 
  rename(intercept_residual2 = `(Intercept)`) %>%
  as_tibble()

PSYC746_final <- full_join(PSYC746_final, l2_residuals_rowname2) 

PSYC746_final %>%
  ggplot() + 
  geom_point(mapping = aes(x = l1resid, y = intercept_residual2))
cor.test(PSYC746_final$l1resid, PSYC746_final$intercept_residual2) 
```
   
There is a significant correlation between L1 residuals and the random intercept by item, although the correlation is very close to 0 (p = .09).

*Relatedness of l1_residuals and l2_rL1 duals (slope pL2 icipants)*
```{r, echo = FALSE, warning = FALSE, fig.width=6, fig.heigmessage = FALSE, ht = 4}
PSYC746_final %>%
  ggplot() + 
  geom_point(mapping = aes(x = l1resid, y = slope_residual))
cor.test(PSYC746_final$l1resid, PSYC746_final$slope_residual) 
```

There is no significant correlation between L1 residuals and L2 residuals (random slope for Context by participant). 

##### Relatedness L2 residuals and L2 residuals

**L2 intercept (participant)-L2 slope (participants)**   

```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix %>% ggplot(mapping = aes(x = L2resid_p, y = L2resid_slope)) +
  geom_point() +
  labs(x = "Intercept participants", y = "Slope Context by participant")
cor.test(l2_mix$L2resid_p, l2_mix$L2resid_slope) 
```
   
There is a moderate negative correlation (significant), suggesting that the higher the mean log TRT value for an individual (i.e., the slower the individual), the smaller the effect of context for this individual. This is a violation of the assumption of independence of errors.

**L2 intercept (participant)-L2 intercept (item)**   

```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix2 <- merge(l2_mix, l2_residuals_rowname_i, by = "ITEM")
l2_mix2 %>% ggplot(mapping = aes(x = L2resid_p, y = L2resid_i)) +
  geom_point() +
  labs(x = "Intercept participants", y = "Intercept items")
cor.test(l2_mix2$L2resid_p, l2_mix2$L2resid_i)
```
   
There is no correlation between the random intercept by participant and the random intercept by item. 

**L2 intercept (items)-L2 slope (participants)**   

```{r, echo = FALSE, fig.width=6, fig.height = 4}
l2_mix2 %>% ggplot(mapping = aes(x = L2resid_i, y = L2resid_slope)) +
  geom_point() +
  labs(x = "Intercept items", y = "Slope Context by participant")
cor.test(l2_mix2$L2resid_i, l2_mix2$L2resid_slope) 
```
   
There is no correlation between the random intercept by item and the random slope for Context by item.

# <span style="color: purple;">6. Conclusion</span> 

In conclusion, we have found that bilingual older adults do process ambiguous words differently when they are embedded in sentences that include a modifier clarifying their meaning. This effect did not vary significantly across participants. There was also no significant difference in terms of processing speed between English-French and French-English bilinguals. Whether English was the first or the second language did not modulate the processing of ambiguous words. Finally, the effect of sentence context did not vary across language groups, suggesting that context does impacts the processing of ambiguous words regardless of native language in bilingual older adults.

It should be noted that all participants were highly fluent in English, which may partially explain the absence of native language effect. However, the effects of native language and the interaction of native language were both borderline approached significance, which suggests that the study may have been underpowered (as a reminder, there were 32 participants). 
